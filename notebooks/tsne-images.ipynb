{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://wandb.ai/ml43d/3dpart-simclr/runs/21070614442839/files/3dpart-simclr/21070614442839/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0, parentdir) \n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shepherd/anaconda3/lib/python3.7/site-packages/pl_bolts/utils/warnings.py:32: UserWarning: You want to use `wandb` which is not installed yet, install it with `pip install wandb`.\n",
      "  f' install it with `pip install {pypi_name}`.' + extra_text\n",
      "/home/shepherd/anaconda3/lib/python3.7/site-packages/pl_bolts/utils/warnings.py:32: UserWarning: You want to use `gym` which is not installed yet, install it with `pip install gym`.\n",
      "  f' install it with `pip install {pypi_name}`.' + extra_text\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "from datasets.shapenet_parts.shapenet_parts import ShapeNetParts\n",
    "from datasets.data_modules import PartSegmentationDataModule\n",
    "\n",
    "from models.pointnet import PointNetSegmentation\n",
    "from pointnet_module import SupervisedPointNet\n",
    "from simclr_module import SimCLR\n",
    "from util.visualization_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model with saved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "#limit_ratio = 0.8\n",
    "\n",
    "dm = PartSegmentationDataModule(batch_size)\n",
    "seg_class_map = dm.seg_class_map\n",
    "num_seg_classes = dm.num_seg_classes\n",
    "num_classes = dm.num_classes\n",
    "\n",
    "test_dataloader = dm.test_dataloader()\n",
    "plmodel = SupervisedPointNet(gpus=1,batch_size=batch_size,seg_class_map=seg_class_map)\n",
    "plmodel = plmodel.load_from_checkpoint(checkpoint_path=\"./checkpoints/supervised_no_aug_best_21071320395666.ckpt\")\n",
    "\n",
    "ss_simclr_model = SimCLR(gpus=1,\n",
    "                         batch_size=batch_size,\n",
    "                         dataset='shapenet',\n",
    "                         num_samples = len(test_dataloader)*batch_size)\n",
    "ss_simclr_model = ss_simclr_model.load_from_checkpoint(checkpoint_path=\"./checkpoints/simclr_best_21071416584428.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_latent_space_and_label(plmodel,data_loader,batch_size=8,save_suffix='',quick_load=True,file_to_load=None,ss=False):\n",
    "    num_features = 2048\n",
    "    z_y = np.zeros((len(data_loader)*batch_size,num_features+1))\n",
    "    imgs = []\n",
    "    if not quick_load or file_to_load==None:\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        plmodel = plmodel.to(device)\n",
    "        plmodel.eval()\n",
    "        if ss:\n",
    "            encoder = plmodel.encoder\n",
    "        else:\n",
    "            encoder = plmodel.model.encoder\n",
    "        with torch.no_grad():\n",
    "            i = 0\n",
    "            for batch_index,batch in enumerate(data_loader):\n",
    "                x,_,img,cls_id = batch\n",
    "                x = x.to(device)\n",
    "                cls_id = cls_id.to(device)\n",
    "                out_max,concat,trans_feat = encoder(x)\n",
    "                end = i + batch_size\n",
    "                z_y[i:end] = torch.cat((out_max.detach().cpu(),cls_id.detach().cpu().unsqueeze(1)),1)\n",
    "                imgs += img\n",
    "                i = end\n",
    "        print(z_y.shape)\n",
    "        with open('z_y_{}.npy'.format(save_suffix), 'wb') as f:\n",
    "            np.save(f, z_y)\n",
    "    else:\n",
    "        z_y = np.load(file_to_load)\n",
    "    return z_y,np.array(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def tsne(x,y,n_iter = 5000,perplexity=50):\n",
    "    time_start = time.time()\n",
    "    tsne = TSNE(n_components=2, verbose=0, perplexity=perplexity, n_iter=n_iter)\n",
    "    tsne_results = tsne.fit_transform(x)\n",
    "    print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "    return (tsne_results[:,0], tsne_results[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2872, 2049)\n"
     ]
    }
   ],
   "source": [
    "z_y,imgs = get_latent_space_and_label(plmodel,\n",
    "                       test_dataloader,\n",
    "                       batch_size=batch_size,\n",
    "                       save_suffix='supervised',quick_load=False,\n",
    "                       file_to_load='z_y_supervised.npy')\n",
    "x = z_y[:,:-1]\n",
    "y = z_y[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2872"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now first apply PCA to decrease the number of dimensions before applying t-SNE.\n",
    "And we get ~91 percent explained variation in the data. It is a pretty good explanation of the data. Let's apply t-SNE to this data alongside to original data to see what we can get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 50, Number of Iterations: 5000 ...\n",
      "t-SNE done! Time elapsed: 137.20383191108704 seconds\n",
      "0/2000\n",
      "100/2000\n",
      "200/2000\n",
      "300/2000\n",
      "400/2000\n",
      "500/2000\n",
      "600/2000\n",
      "700/2000\n",
      "800/2000\n",
      "900/2000\n",
      "1000/2000\n",
      "1100/2000\n",
      "1200/2000\n",
      "1300/2000\n",
      "1400/2000\n",
      "1500/2000\n",
      "1600/2000\n",
      "1700/2000\n",
      "1800/2000\n",
      "1900/2000\n"
     ]
    }
   ],
   "source": [
    "#pca_50 = PCA(n_components=50)\n",
    "#pca_result_50 = pca_50.fit_transform(x)\n",
    "#print('Cumulative explained variation for 50 principal components: {}'.format(np.sum(pca_50.explained_variance_ratio_)))\n",
    "\n",
    "n_iters = [5000]\n",
    "perplexities = [50]\n",
    "for n_iter in n_iters:\n",
    "    for perplexity in perplexities:\n",
    "        print('Perplexity: {}, Number of Iterations: {} ...'.format(perplexity,n_iter))\n",
    "        tsne_x,tsne_y = tsne(x,y,n_iter=n_iter,perplexity=perplexity)\n",
    "        #plot_tsne_points(tsne_x,tsne_y,plot_save_suffix='supervised')\n",
    "        visualize_tsne_with_pictures(tsne_x,tsne_y,imgs,n_images=2000,S=6000,s=70,background=255)\n",
    "        #tsne(pca_result_50,y,n_iter=n_iter,perplexity=perplexity, plot_save_suffix='supervised_pca_applied')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2872, 2049)\n"
     ]
    }
   ],
   "source": [
    "# Self Supervised\n",
    "z_y_ss,imgs_ss = get_latent_space_and_label(ss_simclr_model,\n",
    "                       test_dataloader,\n",
    "                       batch_size=batch_size,\n",
    "                       save_suffix='self_supervised_best',\n",
    "                       file_to_load='z_y_self_supervised.npy',\n",
    "                                    quick_load=False,\n",
    "                                    ss=True)\n",
    "\n",
    "x_ss = z_y_ss[:,:-1]\n",
    "y_ss = z_y_ss[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 50, Number of Iterations: 5000 ...\n",
      "t-SNE done! Time elapsed: 122.08724641799927 seconds\n",
      "0/2000\n",
      "100/2000\n",
      "200/2000\n",
      "300/2000\n",
      "400/2000\n",
      "500/2000\n",
      "600/2000\n",
      "700/2000\n",
      "800/2000\n",
      "900/2000\n",
      "1000/2000\n",
      "1100/2000\n",
      "1200/2000\n",
      "1300/2000\n",
      "1400/2000\n",
      "1500/2000\n",
      "1600/2000\n",
      "1700/2000\n",
      "1800/2000\n",
      "1900/2000\n"
     ]
    }
   ],
   "source": [
    "#pca_50_ss = PCA(n_components=50)\n",
    "#pca_result_50_ss = pca_50_ss.fit_transform(x_ss)\n",
    "#print('Cumulative explained variation for 50 principal components: {}'.format(np.sum(pca_50_ss.explained_variance_ratio_)))\n",
    "\n",
    "n_iters = [5000]\n",
    "perplexities = [50]\n",
    "for n_iter in n_iters:\n",
    "    for perplexity in perplexities:\n",
    "        print('Perplexity: {}, Number of Iterations: {} ...'.format(perplexity,n_iter))\n",
    "        tsne_x,tsne_y = tsne(x_ss,y_ss,n_iter=n_iter,perplexity=perplexity)\n",
    "        #plot_tsne_points(tsne_x,tsne_y,plot_save_suffix='ss_2676_epoch_150')\n",
    "        visualize_tsne_with_pictures(tsne_x,tsne_y,imgs_ss,n_images=2000,S=6000,s=70,background=255)\n",
    "        #tsne(pca_result_50_ss,y_ss,n_iter=n_iter,perplexity=perplexity, plot_save_suffix='ss_2676_epoch_0_pca_applied')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python374jvsc74a57bd0526fdff7b650bbc232b2b5da034e6c2aa52b9ebe53e736c16abc2aa88bdfa19d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
