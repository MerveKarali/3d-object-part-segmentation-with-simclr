{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a16fca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bbf2430",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mert/venvs/ml43d/lib/python3.7/site-packages/pytorch_lightning/metrics/__init__.py:44: LightningDeprecationWarning: `pytorch_lightning.metrics.*` module has been renamed to `torchmetrics.*` and split off to its own package (https://github.com/PyTorchLightning/metrics) since v1.3 and will be removed in v1.5\n",
      "  \"`pytorch_lightning.metrics.*` module has been renamed to `torchmetrics.*` and split off to its own package\"\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import numpy as np\n",
    "from pointnet_module import SupervisedPointNet\n",
    "from datasets.shapenet_parts.shapenet_parts import ShapeNetParts\n",
    "from util.visualization_utils import visualize_pointcloud\n",
    "from matplotlib import cm, colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5317e062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mert/Documents/projects/ml43d/3d-object-part-segmentation-with-simclr\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "model = SupervisedPointNet.load_from_checkpoint('supervised_best.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7544dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2500])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mert/venvs/ml43d/lib/python3.7/site-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"int64\" does not match required type \"uint32\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55117804adfe41d495af47dbd4289b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = ShapeNetParts('test', transforms=None)\n",
    "\n",
    "sample, gt_seg, gt_cls = test_dataset[700]\n",
    "print(sample.shape)\n",
    "\n",
    "shape_points = sample.T\n",
    "\n",
    "point_labels = (gt_seg - min(gt_seg)) / (max(gt_seg) - min(gt_seg))\n",
    "point_colors = cm.get_cmap('hsv')(point_labels)[:, :3]\n",
    "point_colors = np.sum((point_colors * 255).astype(int) * [255*255, 255, 1], axis=1)\n",
    "visualize_pointcloud(shape_points.numpy(), colors=point_colors, point_size=0.025, flip_axes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac5a0c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'augmentations.augmentations.GaussianNoise'>\n",
      "torch.Size([3, 2500])\n",
      "torch.Size([2500])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7d1367c1e4e4445b775a31955f5fd33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'augmentations.augmentations.Rescale'>\n",
      "torch.Size([3, 2500])\n",
      "torch.Size([2500])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "473a8ba7c64c4170a8d49d4239095def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'augmentations.augmentations.Flip'>\n",
      "torch.Size([3, 2500])\n",
      "torch.Size([2500])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e7bb3976454ef18b00d47cc0f05402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'augmentations.augmentations.RandomDrop'>\n",
      "torch.Size([3, 2500])\n",
      "torch.Size([2500])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb10993170647f1a5272b33158f1106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'augmentations.augmentations.Rotation'>\n",
      "torch.Size([3, 2500])\n",
      "torch.Size([2500])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d345f6692f3a4cf89c514cf05e3b2c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transforms import SimCLREvalDataTransform\n",
    "from augmentations.augmentations import Rescale, Flip, GaussianNoise, RandomDrop, Rotation\n",
    "\n",
    "transformations = [\n",
    "    #None,\n",
    "    GaussianNoise,\n",
    "    Rescale,\n",
    "    Flip,\n",
    "    RandomDrop,\n",
    "    Rotation\n",
    "]\n",
    "\n",
    "for transform in transformations:\n",
    "    print(str(transform))\n",
    "    if transform:  \n",
    "        tranformation_compositions = SimCLREvalDataTransform([transform(p=1)])\n",
    "    else:\n",
    "        tranformation_compositions = None\n",
    "        \n",
    "    model.eval()\n",
    "    model.freeze()\n",
    "\n",
    "    test_dataset = ShapeNetParts('test', transforms=tranformation_compositions)\n",
    "    (sample,_,_), gt_seg, gt_cls = test_dataset[200]\n",
    "    \n",
    "    print(sample.shape)\n",
    "\n",
    "    gt_cls_tensor = torch.tensor([gt_cls])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = model.inference_step(sample.unsqueeze(0), gt_cls_tensor)\n",
    "    print(prediction.shape)\n",
    "    shape_points = sample.T\n",
    "\n",
    "    point_labels = (prediction - min(prediction)) / (max(prediction) - min(prediction))\n",
    "    point_colors = cm.get_cmap('hsv')(point_labels)[:, :3]\n",
    "    point_colors = np.sum((point_colors * 255).astype(int) * [255*255, 255, 1], axis=1)\n",
    "    visualize_pointcloud(shape_points.numpy(), colors=point_colors, point_size=0.025, flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fab462b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NO AUGMENTATION DATASET SINGLE INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6841c660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2500])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.freeze()\n",
    "\n",
    "test_dataset = ShapeNetParts('test', transforms=None)\n",
    "\n",
    "sample, gt_seg, gt_cls = test_dataset[700]\n",
    "\n",
    "gt_cls_tensor = torch.tensor([gt_cls])\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = model.inference_step(sample.unsqueeze(0), gt_cls_tensor)\n",
    "print(prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58f83904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285d6442ca2549068c4eb95fbeb486ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shape_points = sample.T\n",
    "\n",
    "point_labels = (prediction - min(prediction)) / (max(prediction) - min(prediction))\n",
    "point_colors = cm.get_cmap('hsv')(point_labels)[:, :3]\n",
    "point_colors = np.sum((point_colors * 255).astype(int) * [255*255, 255, 1], axis=1)\n",
    "visualize_pointcloud(shape_points.numpy(), colors=point_colors, point_size=0.025, flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597f65f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
